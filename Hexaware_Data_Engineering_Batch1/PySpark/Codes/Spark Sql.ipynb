{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13cb1749-087c-4bf8-a5c3-6e0f66ee25e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c7fdc7-ff34-439d-ae75-a046221a0d96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"firstsession\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a08640b-5bea-44aa-ba07-676bfcc030b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[16]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# Creating Database in spark sql\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b070ddbb-b6b5-4ced-90e7-c763aeaff32b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[18]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# Creating table \n",
    "\n",
    "spark.sql(\"CREATE TABLE if not exists ct.sampleTable (number Int, word String)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796f27e6-2bf0-4aff-b29d-fcf0f1ad9b87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO ct.sampleTable VALUES (124,'Yogita Yeole')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f00ff92e-4310-4eed-acc9-ed24ffc59715",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n|number|        word|\n+------+------------+\n|   124|Yogita Yeole|\n|   123| Pratik Wani|\n+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM ct.sampleTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e440da-965b-4a47-accc-102fcf01cfae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[25]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "# Alter Table \n",
    "spark.sql(\"ALTER TABLE ct.sampleTable ADD columns (salary int, DOB timestamp);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e8eb47-0cfc-4aaf-97d5-0f5bdd20e989",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------+-------------------+\n|number|        word|salary|                DOB|\n+------+------------+------+-------------------+\n|   123| Pratik Wani|100000|2002-03-10 00:00:00|\n|   124|Yogita Yeole|100000|               null|\n+------+------------+------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from ct.sampletable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8878178-7c42-49c0-bc72-78e27ed76936",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[34]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"use ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfb14470-1c31-4f4e-8761-8da4c2250811",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[41]: DataFrame[num_affected_rows: bigint]"
     ]
    }
   ],
   "source": [
    "# Updating the records\n",
    "\n",
    "spark.sql(\"UPDATE ct.sampletable set salary=100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e29b41c-2ce5-4709-b2fc-c34e301ccb19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[43]: DataFrame[num_affected_rows: bigint]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"UPDATE ct.sampletable set DOB='2002-03-10' where number=123 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26cd473d-fa88-4ea5-8fa6-04ba354b7701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[45]: DataFrame[num_affected_rows: bigint]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"UPDATE ct.sampletable set DOB='1995-06-24' where number=124 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55ff1ad2-ab20-402a-b4f6-66349699aaf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------+-------------------+\n|number|        word|salary|                DOB|\n+------+------------+------+-------------------+\n|   124|Yogita Yeole|100000|1995-06-24 00:00:00|\n|   123| Pratik Wani|100000|2002-03-10 00:00:00|\n+------+------------+------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from ct.sampletable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfa30efe-956a-48e5-9165-b1d0a2704f0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[51]: DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
     ]
    }
   ],
   "source": [
    "# inserted more data in table\n",
    "\n",
    "spark.sql(\"INSERT INTO ct.sampletable (number, word, salary, DOB) VALUES\\\n",
    "(125, 'John Doe', 80000, '1990-05-15 00:00:00'),\\\n",
    "(126, 'Jane Smith', 90000, '1988-11-28 00:00:00'),\\\n",
    "(127, 'Alice Johnson', 95000, '1993-09-10 00:00:00'),\\\n",
    "(128, 'Bob Brown', 85000, '1995-03-20 00:00:00'),\\\n",
    "(129, 'Emily Davis', 82000, '1997-07-05 00:00:00'),\\\n",
    "(130, 'Michael Wilson', 87000, '1985-12-12 00:00:00'),\\\n",
    "(131, 'Sarah Miller', 91000, '1982-04-30 00:00:00'),\\\n",
    "(132, 'David Garcia', 92000, '1989-08-18 00:00:00'),\\\n",
    "(133, 'Jessica Martinez', 93000, '1991-02-25 00:00:00'),\\\n",
    "(134, 'Daniel Taylor', 94000, '1998-06-08 00:00:00');\\\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcb9ec26-21af-4eee-83b5-6c3a21237f19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|count(1)|\n+--------+\n|      12|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows in table\n",
    "spark.sql(\"select count(*) from ct.sampletable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8724cd8-8f2c-40c9-b66d-44ebf2ab2913",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------+-------------------+\n|number|            word|salary|                DOB|\n+------+----------------+------+-------------------+\n|   123|     Pratik Wani|100000|2002-03-10 00:00:00|\n|   124|    Yogita Yeole|100000|1995-06-24 00:00:00|\n|   127|   Alice Johnson| 95000|1993-09-10 00:00:00|\n|   134|   Daniel Taylor| 94000|1998-06-08 00:00:00|\n|   133|Jessica Martinez| 93000|1991-02-25 00:00:00|\n|   132|    David Garcia| 92000|1989-08-18 00:00:00|\n|   131|    Sarah Miller| 91000|1982-04-30 00:00:00|\n|   126|      Jane Smith| 90000|1988-11-28 00:00:00|\n|   130|  Michael Wilson| 87000|1985-12-12 00:00:00|\n|   128|       Bob Brown| 85000|1995-03-20 00:00:00|\n|   129|     Emily Davis| 82000|1997-07-05 00:00:00|\n|   125|        John Doe| 80000|1990-05-15 00:00:00|\n+------+----------------+------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#  Sorted the data salary wise \n",
    "\n",
    "spark.sql(\"select * from ct.sampletable order by salary desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5a6f34-bd8f-4fe2-8d65-bd1329c2598c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[55]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"alter table ct.sampletable add column (department string)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c66c37-1f0b-4d2b-b5f1-0a02b1715c64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[56]: DataFrame[num_affected_rows: bigint]"
     ]
    }
   ],
   "source": [
    "# Updating the data in new added columns\n",
    "\n",
    "spark.sql(\"update ct.sampletable set department='Data Engineeing' where number In(123,124,125,126)\")\n",
    "spark.sql(\"update ct.sampletable set department='Developers' where number In(127,128,129,130)\")\n",
    "spark.sql(\"update ct.sampletable set department='Testers' where number In(131,132,133,134)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24d62408-20b9-4600-827e-69836c29b981",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n|     department|max(salary)|\n+---------------+-----------+\n|     Developers|      95000|\n|        Testers|      94000|\n|Data Engineeing|     100000|\n+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Department wise maximun salary\n",
    "spark.sql(\"select department, max(salary) from ct.sampletable group by department\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cb6e3ff-faef-4b74-9a58-3d0596946761",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create data frame\n",
    "df = spark.read.csv(\"/FileStore/tables/student_salary_info-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac827999-7f6b-4c51-8040-2b02f203b685",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# created a temp view\n",
    "df.createOrReplaceTempView('Student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddf241c8-574b-4886-b37c-8dbf7dfed488",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n|   _c0|_c1|   _c2|\n+------+---+------+\n|  Name|Age|Salary|\n|Pratik| 21| 50000|\n| Vikas| 23|100000|\n| Rushi| 22|120000|\n+------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from Student\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark Sql",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

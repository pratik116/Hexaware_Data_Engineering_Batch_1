{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "470a05d5-604f-44cd-9fc8-c6ce7682a1cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1de6ba1a-7e67-4bee-8757-15e3d6b6daca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Coding_assisment').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52902087-1209-43a8-9a19-ba829013ac6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+-------+\n| ID|  Name|Age|   City|\n+---+------+---+-------+\n|  1|Pratik| 22| Nashik|\n|  2| Vikas| 24|   Pune|\n|  3| Rushi| 23|Chicago|\n+---+------+---+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Dataframe 1\n",
    "Data1=[(1, \"Pratik\", 22, \"Nashik\"),\n",
    "       (2, \"Vikas\", 24, \"Pune\"),\n",
    "       (3, \"Rushi\", 23, \"Chicago\")]\n",
    "Header1=[\"ID\", \"Name\", \"Age\", \"City\"]\n",
    "df1=spark.createDataFrame(Data1, Header1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d6ac90-f230-4b48-8edb-a790279290a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-------+\n| ID|              Role| Salary|\n+---+------------------+-------+\n|  1|     Data Engineer|4000000|\n|  2|Software Developer|3500000|\n|  3|            Tester|2000000|\n+---+------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#DataFrame 2\n",
    "Data2 = [(1, \"Data Engineer\", 4000000),\n",
    "         (2, \"Software Developer\", 3500000),\n",
    "         (3, \"Tester\", 2000000)]\n",
    "Header2 = [\"ID\", \"Role\", \"Salary\"]\n",
    "df2=spark.createDataFrame(Data2, Header2)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b08d7bf4-98d3-4e1e-85d6-1aa08a7a0490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+-------+\n| ID|  Name|Age|   City|\n+---+------+---+-------+\n|  1|Pratik| 22| Nashik|\n|  2| Vikas| 24|   Pune|\n|  3| Rushi| 23|Chicago|\n|  4|Yogita| 30| Nashik|\n+---+------+---+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Manipulating data \n",
    "\n",
    "newData=(4,\"Yogita\",30, \"Nashik\")\n",
    "df1 = df1.union(spark.createDataFrame([newData]))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a59df1ef-4708-4710-a126-2a6a515e1ea2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted DataFrame1 by Age in Ascending Order:\n+---+------+---+-------+\n| ID|  Name|Age|   City|\n+---+------+---+-------+\n|  1|Pratik| 22| Nashik|\n|  3| Rushi| 23|Chicago|\n|  2| Vikas| 24|   Pune|\n|  4|Yogita| 30| Nashik|\n+---+------+---+-------+\n\nSorted Dataframe3 by Salary in Descending Order:\n+---+------------------+-------+\n| ID|              Role| Salary|\n+---+------------------+-------+\n|  1|     Data Engineer|4000000|\n|  2|Software Developer|3500000|\n|  3|            Tester|2000000|\n+---+------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Sorting the Dataframe 1 by age and Dataframe 2 by salary\n",
    "\n",
    "sorted_df1 = df1.orderBy(\"Age\")\n",
    "sorted_df2 = df2.orderBy(col(\"Salary\").desc())\n",
    "print(\"Sorted DataFrame1 by Age in Ascending Order:\")\n",
    "sorted_df1.show()\n",
    "print(\"Sorted Dataframe3 by Salary in Descending Order:\")\n",
    "sorted_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d0d79c2-a2da-41fa-8753-f7f712450e08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined DataFrame1 and Dataframe2:\n+---+------+---+-------+------------------+-------+\n| ID|  Name|Age|   City|              Role| Salary|\n+---+------+---+-------+------------------+-------+\n|  1|Pratik| 22| Nashik|     Data Engineer|4000000|\n|  2| Vikas| 24|   Pune|Software Developer|3500000|\n|  3| Rushi| 23|Chicago|            Tester|2000000|\n+---+------+---+-------+------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Joining two Dataframes bases on the ID column ( INNER JOIN )\n",
    "\n",
    "joined_df = df1.join(df2, \"ID\", \"inner\")\n",
    "print(\"Joined DataFrame1 and Dataframe2:\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd9a7d46-a710-48c1-91cc-a37b094581a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped DataFrame:\n+-------+-----+\n|   City|count|\n+-------+-----+\n| Nashik|    2|\n|   Pune|    1|\n|Chicago|    1|\n+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Group by Dataframe to count the total employee from each City\n",
    "\n",
    "grouped_df = df1.groupBy(\"City\").count()\n",
    "print(\"Grouped DataFrame:\")\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d9317c-ecd9-4dcd-b683-36cd673270d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grand Total: \n+-----------+\n|sum(Salary)|\n+-----------+\n|    9500000|\n+-----------+\n\nCity wise Avg age: \n+--------+\n|avg(Age)|\n+--------+\n|   24.75|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Aggregations\n",
    "# Grand Total Salary \n",
    "Grand_total=df2.groupBy().sum(\"Salary\")\n",
    "print(\"Grand Total: \")\n",
    "Grand_total.show()\n",
    "\n",
    "# Calulate City wise Avarage age of emplyees \n",
    "Avg_age=df1.groupBy().avg(\"Age\")\n",
    "print(\"City wise Avg age: \")\n",
    "Avg_age.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f72967-c4da-4f75-b0d1-f914dc7fbbc9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame1: \n+---+------+---+\n| ID|  Name|Age|\n+---+------+---+\n|  1|Pratik| 22|\n|  2| Vikas| 24|\n|  3| Rushi| 23|\n|  4|Yogita| 30|\n+---+------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Droping a column city from DataFrame1\n",
    "Droped_df1=df1.drop(\"City\")\n",
    "print(\"New DataFrame1: \")\n",
    "Droped_df1.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Coding Assessment_ Question 1 2024-02-12 10:29:36",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
